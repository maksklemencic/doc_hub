import uuid
from datetime import datetime
from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Field, ConfigDict

from .shared import PaginationMetadata


class MessageStatus(str, Enum):
    PENDING = "pending"
    STREAMING = "streaming"
    COMPLETED = "completed"
    FAILED = "failed"

class RateLimitInfo(BaseModel):
    requests_per_minute_limit: int
    current_minute_requests: int
    requests_remaining: int
    requests_reset_time: Optional[str] = None
    tokens_per_minute_limit: Optional[int] = None
    current_minute_tokens: Optional[int] = None
    rate_limits_dynamic: bool = True

class LLMResponse(BaseModel):
    query: str = Field(..., description="The original query sent to the LLM.")
    response: str = Field(..., description="The response generated by the LLM.")
    context: str = Field(..., description="Context used for generating the response.")
    rate_limits: Optional[RateLimitInfo] = Field(None, description="Current rate limit information.")

class MessageResponse(BaseModel):
    # Core fields
    id: uuid.UUID = Field(..., description="Unique identifier (UUID) of the message.")
    space_id: uuid.UUID = Field(..., description="Identifier of the space the message belongs to.")
    user_id: uuid.UUID = Field(..., description="Identifier of the user who created the message.")
    content: str = Field(..., description="The content of the message.")
    response: Optional[str] = Field(None, description="The AI response to the message.")

    # Status and timing fields
    status: MessageStatus = Field(MessageStatus.PENDING, description="Current status of the message.")
    created_at: datetime = Field(..., description="Timestamp when the message was created.")

    model_config = ConfigDict(from_attributes=True)

class MessageResponseWrapper(BaseModel):
    data: LLMResponse = Field(..., description="The response data containing the query, response, and context.")
    message: MessageResponse = Field(..., description="The message object containing metadata about the created message.")

class CreateMessageRequest(BaseModel):
    content: str = Field(..., description="The content of the message to create.")
    top_k: int = Field(5, ge=1, le=100, description="Number of top results to return when using context.")
    use_context: bool = Field(True, description="Whether to use context from the RAG system.")
    only_space_documents: bool = Field(True, description="Whether to restrict context to documents within the same space.")


class UpdateMessageRequest(BaseModel):
    content: str = Field(..., min_length=1, description="The new content of the message.")
    response: Optional[str] = Field(None, description="The new AI response to the message.")
    
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "content": "What are the key points in document X regarding Y?",
                "response": "Based on the documents, the key points are..."
            }
        }
    )

class GetMessagesRequest(BaseModel):
    limit: int = Field(10, ge=1, le=100, description="Number of messages to return per page.")
    offset: int = Field(0, ge=0, description="Number of messages to skip before starting the page.")

class GetMessagesResponseWrapper(BaseModel):
    messages: List[MessageResponse]
    pagination: PaginationMetadata = Field(..., description="Pagination metadata including limit, offset, and total count.")

