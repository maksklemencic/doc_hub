[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Form",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "FileResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "exc",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "Column",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "TIMESTAMP",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "ForeignKey",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "text",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "sessionmaker",
        "importPath": "sqlalchemy.orm",
        "description": "sqlalchemy.orm",
        "isExtraImport": true,
        "detail": "sqlalchemy.orm",
        "documentation": {}
    },
    {
        "label": "sessionmaker",
        "importPath": "sqlalchemy.orm",
        "description": "sqlalchemy.orm",
        "isExtraImport": true,
        "detail": "sqlalchemy.orm",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "pytesseract",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytesseract",
        "description": "pytesseract",
        "detail": "pytesseract",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "docx",
        "description": "docx",
        "isExtraImport": true,
        "detail": "docx",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "RecursiveChunker",
        "importPath": "chonkie",
        "description": "chonkie",
        "isExtraImport": true,
        "detail": "chonkie",
        "documentation": {}
    },
    {
        "label": "detect",
        "importPath": "langdetect",
        "description": "langdetect",
        "isExtraImport": true,
        "detail": "langdetect",
        "documentation": {}
    },
    {
        "label": "KeyBERT",
        "importPath": "keybert",
        "description": "keybert",
        "isExtraImport": true,
        "detail": "keybert",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "QdrantClient",
        "importPath": "qdrant_client",
        "description": "qdrant_client",
        "isExtraImport": true,
        "detail": "qdrant_client",
        "documentation": {}
    },
    {
        "label": "VectorParams",
        "importPath": "qdrant_client.http.models",
        "description": "qdrant_client.http.models",
        "isExtraImport": true,
        "detail": "qdrant_client.http.models",
        "documentation": {}
    },
    {
        "label": "Distance",
        "importPath": "qdrant_client.http.models",
        "description": "qdrant_client.http.models",
        "isExtraImport": true,
        "detail": "qdrant_client.http.models",
        "documentation": {}
    },
    {
        "label": "PointStruct",
        "importPath": "qdrant_client.http.models",
        "description": "qdrant_client.http.models",
        "isExtraImport": true,
        "detail": "qdrant_client.http.models",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "qdrant_client.http",
        "description": "qdrant_client.http",
        "isExtraImport": true,
        "detail": "qdrant_client.http",
        "documentation": {}
    },
    {
        "label": "debugpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "debugpy",
        "description": "debugpy",
        "detail": "debugpy",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "sqlalchemy.dialects.postgresql",
        "description": "sqlalchemy.dialects.postgresql",
        "isExtraImport": true,
        "detail": "sqlalchemy.dialects.postgresql",
        "documentation": {}
    },
    {
        "label": "declarative_base",
        "importPath": "sqlalchemy.ext.declarative",
        "description": "sqlalchemy.ext.declarative",
        "isExtraImport": true,
        "detail": "sqlalchemy.ext.declarative",
        "documentation": {}
    },
    {
        "label": "chunk_text",
        "kind": 2,
        "importPath": "backend.app.debug.doc_pipline",
        "description": "backend.app.debug.doc_pipline",
        "peekOfCode": "def chunk_text(text: str, chunk_size=500, chunk_overlap=50):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap\n    )\n    chunks = text_splitter.split_text(text)\n    return chunks\ndef get_embeddings(chunks: list) -> list:\n    return model.encode(chunks)\nwith open(\"./backend/app/debug/document_sample.txt\", \"r\", encoding=\"utf-8\") as f:",
        "detail": "backend.app.debug.doc_pipline",
        "documentation": {}
    },
    {
        "label": "get_embeddings",
        "kind": 2,
        "importPath": "backend.app.debug.doc_pipline",
        "description": "backend.app.debug.doc_pipline",
        "peekOfCode": "def get_embeddings(chunks: list) -> list:\n    return model.encode(chunks)\nwith open(\"./backend/app/debug/document_sample.txt\", \"r\", encoding=\"utf-8\") as f:\n    text = f.read()\nchunks = chunk_text(text)\nprint(f\"Total chunks created: {len(chunks)}\")\n# print(chunks[0])\nembeddings = get_embeddings(chunks)\n# list (125, 384)\nprint(\"Done\")",
        "detail": "backend.app.debug.doc_pipline",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "backend.app.debug.doc_pipline",
        "description": "backend.app.debug.doc_pipline",
        "peekOfCode": "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\ndef chunk_text(text: str, chunk_size=500, chunk_overlap=50):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap\n    )\n    chunks = text_splitter.split_text(text)\n    return chunks\ndef get_embeddings(chunks: list) -> list:\n    return model.encode(chunks)",
        "detail": "backend.app.debug.doc_pipline",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 5,
        "importPath": "backend.app.debug.doc_pipline",
        "description": "backend.app.debug.doc_pipline",
        "peekOfCode": "chunks = chunk_text(text)\nprint(f\"Total chunks created: {len(chunks)}\")\n# print(chunks[0])\nembeddings = get_embeddings(chunks)\n# list (125, 384)\nprint(\"Done\")",
        "detail": "backend.app.debug.doc_pipline",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "backend.app.debug.doc_pipline",
        "description": "backend.app.debug.doc_pipline",
        "peekOfCode": "embeddings = get_embeddings(chunks)\n# list (125, 384)\nprint(\"Done\")",
        "detail": "backend.app.debug.doc_pipline",
        "documentation": {}
    },
    {
        "label": "PostQueryRequest",
        "kind": 6,
        "importPath": "backend.app.routes.chat",
        "description": "backend.app.routes.chat",
        "peekOfCode": "class PostQueryRequest(BaseModel):\n    query: str\n    stream: bool = False\n    top_k: int = 5\n    use_context: bool = True\n@router.post(\"/messages/{user_id}\")\ndef create_query(data: PostQueryRequest, user_id: str):\n    try:\n        if user_id is None:\n            raise HTTPException(status_code=404, detail=\"No user_id provided!\")",
        "detail": "backend.app.routes.chat",
        "documentation": {}
    },
    {
        "label": "create_query",
        "kind": 2,
        "importPath": "backend.app.routes.chat",
        "description": "backend.app.routes.chat",
        "peekOfCode": "def create_query(data: PostQueryRequest, user_id: str):\n    try:\n        if user_id is None:\n            raise HTTPException(status_code=404, detail=\"No user_id provided!\")\n        if data.use_context is True:\n            query_embedding = get_embeddings([data.query])[0]\n            top_k_chunks = query_top_k(query_embedding, user_id=user_id, k=data.top_k)\n            context = \"\\n\".join([res.payload[\"text\"] for res in top_k_chunks])\n        else:\n            context = \"/\"",
        "detail": "backend.app.routes.chat",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "backend.app.routes.chat",
        "description": "backend.app.routes.chat",
        "peekOfCode": "router = APIRouter()\nclass PostQueryRequest(BaseModel):\n    query: str\n    stream: bool = False\n    top_k: int = 5\n    use_context: bool = True\n@router.post(\"/messages/{user_id}\")\ndef create_query(data: PostQueryRequest, user_id: str):\n    try:\n        if user_id is None:",
        "detail": "backend.app.routes.chat",
        "documentation": {}
    },
    {
        "label": "GetDocumentRequest",
        "kind": 6,
        "importPath": "backend.app.routes.documents",
        "description": "backend.app.routes.documents",
        "peekOfCode": "class GetDocumentRequest(BaseModel):\n    documentId: str\n@router.get(\"/{doc_id}\")\ndef get_document(data: GetDocumentRequest):\n    pass\n@router.get(\"/view/{doc_id}\")\ndef view_document(doc_id: str):\n    try:\n        doc_uuid = uuid.UUID(doc_id)\n    except ValueError:",
        "detail": "backend.app.routes.documents",
        "documentation": {}
    },
    {
        "label": "get_document",
        "kind": 2,
        "importPath": "backend.app.routes.documents",
        "description": "backend.app.routes.documents",
        "peekOfCode": "def get_document(data: GetDocumentRequest):\n    pass\n@router.get(\"/view/{doc_id}\")\ndef view_document(doc_id: str):\n    try:\n        doc_uuid = uuid.UUID(doc_id)\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid document ID format\")\n    document = db_handler.get_document_by_id(doc_uuid)\n    if not document:",
        "detail": "backend.app.routes.documents",
        "documentation": {}
    },
    {
        "label": "view_document",
        "kind": 2,
        "importPath": "backend.app.routes.documents",
        "description": "backend.app.routes.documents",
        "peekOfCode": "def view_document(doc_id: str):\n    try:\n        doc_uuid = uuid.UUID(doc_id)\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid document ID format\")\n    document = db_handler.get_document_by_id(doc_uuid)\n    if not document:\n        raise HTTPException(status_code=404, detail=\"Document not found\")\n    file_path = document.file_path\n    mime_type, _ = mimetypes.guess_type(document.filename)",
        "detail": "backend.app.routes.documents",
        "documentation": {}
    },
    {
        "label": "delete_document_endpoint",
        "kind": 2,
        "importPath": "backend.app.routes.documents",
        "description": "backend.app.routes.documents",
        "peekOfCode": "def delete_document_endpoint(doc_id: str):\n    try:\n        doc_uuid = uuid.UUID(doc_id)\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid document ID format\")\n    document = db_handler.get_document_by_id(doc_uuid)\n    if not document:\n        raise HTTPException(status_code=404, detail=\"Document not found\")\n    # 1. Delete from filesystem\n    file_path = Path(document.file_path)",
        "detail": "backend.app.routes.documents",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "backend.app.routes.documents",
        "description": "backend.app.routes.documents",
        "peekOfCode": "router = APIRouter()\nclass GetDocumentRequest(BaseModel):\n    documentId: str\n@router.get(\"/{doc_id}\")\ndef get_document(data: GetDocumentRequest):\n    pass\n@router.get(\"/view/{doc_id}\")\ndef view_document(doc_id: str):\n    try:\n        doc_uuid = uuid.UUID(doc_id)",
        "detail": "backend.app.routes.documents",
        "documentation": {}
    },
    {
        "label": "Base64UploadRequest",
        "kind": 6,
        "importPath": "backend.app.routes.upload",
        "description": "backend.app.routes.upload",
        "peekOfCode": "class Base64UploadRequest(BaseModel):\n    filename: str\n    mime_type: str\n    content_base64: str\n    user_id: uuid.UUID\n@router.post(\"/base64\")\ndef upload_base64(request: Base64UploadRequest):\n    try:\n        pages = document_processor.base64_to_text(base64_text=request.content_base64, mime_type=request.mime_type)\n        saved_file_path = file_service.save_base64_file(request.content_base64, request.filename, request.user_id)",
        "detail": "backend.app.routes.upload",
        "documentation": {}
    },
    {
        "label": "upload_base64",
        "kind": 2,
        "importPath": "backend.app.routes.upload",
        "description": "backend.app.routes.upload",
        "peekOfCode": "def upload_base64(request: Base64UploadRequest):\n    try:\n        pages = document_processor.base64_to_text(base64_text=request.content_base64, mime_type=request.mime_type)\n        saved_file_path = file_service.save_base64_file(request.content_base64, request.filename, request.user_id)\n        doc_id = db_handler.add_document(\n            filename=request.filename,\n            file_path=saved_file_path,\n            mime_type=request.mime_type,\n            uploaded_by=request.user_id\n        )",
        "detail": "backend.app.routes.upload",
        "documentation": {}
    },
    {
        "label": "save_to_vector_db",
        "kind": 2,
        "importPath": "backend.app.routes.upload",
        "description": "backend.app.routes.upload",
        "peekOfCode": "def save_to_vector_db(pages: list[(int, str)], filename: str, mime_type: str, document_id: uuid.UUID):\n    # chunks, page_numbers = structure_aware_chunk(pages=pages)\n    chunks, page_numbers = embedding.chunk_pages_with_recursive_chunker(pages=pages)\n    embeddings = embedding.get_embeddings(chunks=chunks)\n    document_id = str(document_id)\n    metadata = metadata_extractor.create_metadata(\n        chunks=chunks, \n        page_numbers=page_numbers, \n        document_id=document_id,\n        filename=filename,",
        "detail": "backend.app.routes.upload",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "backend.app.routes.upload",
        "description": "backend.app.routes.upload",
        "peekOfCode": "router = APIRouter()\nclass Base64UploadRequest(BaseModel):\n    filename: str\n    mime_type: str\n    content_base64: str\n    user_id: uuid.UUID\n@router.post(\"/base64\")\ndef upload_base64(request: Base64UploadRequest):\n    try:\n        pages = document_processor.base64_to_text(base64_text=request.content_base64, mime_type=request.mime_type)",
        "detail": "backend.app.routes.upload",
        "documentation": {}
    },
    {
        "label": "get_document_by_id",
        "kind": 2,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "def get_document_by_id(doc_id: uuid.UUID) -> Document | None:\n    session = SessionLocal()\n    try:\n        doc = session.query(Document).filter(Document.id == doc_id).first()\n        return doc\n    finally:\n        session.close()\ndef add_document(filename: str, file_path: str, mime_type: str, uploaded_by: uuid.UUID) -> uuid.UUID:\n    session = SessionLocal()\n    try:",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "add_document",
        "kind": 2,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "def add_document(filename: str, file_path: str, mime_type: str, uploaded_by: uuid.UUID) -> uuid.UUID:\n    session = SessionLocal()\n    try:\n        doc = Document(\n            filename=filename,\n            file_path=file_path,\n            mime_type=mime_type,\n            uploaded_by=uploaded_by\n        )\n        session.add(doc)",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "update_document",
        "kind": 2,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "def update_document(doc_id: uuid.UUID, **kwargs) -> Document:\n    session = SessionLocal()\n    try:\n        doc = session.get(Document, doc_id)\n        if not doc:\n            raise ValueError(f\"Document with id {doc_id} not found\")\n        for key, value in kwargs.items():\n            if hasattr(doc, key):\n                setattr(doc, key, value)\n        session.commit()",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "delete_document",
        "kind": 2,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "def delete_document(doc_id: uuid.UUID) -> bool:\n    session = SessionLocal()\n    try:\n        doc = session.get(Document, doc_id)\n        if not doc:\n            raise ValueError(f\"Document with id {doc_id} not found\")\n        session.delete(doc)\n        session.commit()\n        return True\n    except exc.SQLAlchemyError as e:",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "DATABASE_URL",
        "kind": 5,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "DATABASE_URL = os.environ.get(\"DATABASE_URL\")\nif not DATABASE_URL:\n    raise ValueError(\"DATABASE_URL is not set in environment\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\ndef get_document_by_id(doc_id: uuid.UUID) -> Document | None:\n    session = SessionLocal()\n    try:\n        doc = session.query(Document).filter(Document.id == doc_id).first()\n        return doc",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "engine",
        "kind": 5,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "engine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\ndef get_document_by_id(doc_id: uuid.UUID) -> Document | None:\n    session = SessionLocal()\n    try:\n        doc = session.query(Document).filter(Document.id == doc_id).first()\n        return doc\n    finally:\n        session.close()\ndef add_document(filename: str, file_path: str, mime_type: str, uploaded_by: uuid.UUID) -> uuid.UUID:",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "SessionLocal",
        "kind": 5,
        "importPath": "backend.app.services.db_handler",
        "description": "backend.app.services.db_handler",
        "peekOfCode": "SessionLocal = sessionmaker(bind=engine)\ndef get_document_by_id(doc_id: uuid.UUID) -> Document | None:\n    session = SessionLocal()\n    try:\n        doc = session.query(Document).filter(Document.id == doc_id).first()\n        return doc\n    finally:\n        session.close()\ndef add_document(filename: str, file_path: str, mime_type: str, uploaded_by: uuid.UUID) -> uuid.UUID:\n    session = SessionLocal()",
        "detail": "backend.app.services.db_handler",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def clean_text(text: str) -> str:\n    text = re.sub(r\"-\\n\", \"\", text)\n    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n    text = re.sub(r\"[ \\t]+\", \" \", text)\n    text = re.sub(r\"[\\x00-\\x1F\\x7F]+\", \"\", text)\n    text = unicodedata.normalize(\"NFKC\", text)\n    return text.strip()\ndef extract_text_from_pdf(file_bytes: bytes) -> List[Tuple[int, str]]:\n    try:\n        doc = fitz.open(stream=file_bytes, filetype=\"pdf\")",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "extract_text_from_pdf",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def extract_text_from_pdf(file_bytes: bytes) -> List[Tuple[int, str]]:\n    try:\n        doc = fitz.open(stream=file_bytes, filetype=\"pdf\")\n    except Exception as e:\n        raise ValueError(f\"Failed to open PDF file: {e}\")\n    page_texts = []\n    for i, page in enumerate(doc):\n        text = page.get_text()\n        if not len(text.strip()) < 5:\n            pix = page.get_pixmap(dpi=300, alpha=False)",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "extract_text_from_docx",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def extract_text_from_docx(file_bytes: bytes) -> List[Tuple[int, str]]:\n    try:\n        doc = Document(io.BytesIO(file_bytes))\n    except Exception as e:\n        raise ValueError(f\"Failed to open DOCX file: {e}\")\n    text_chunks = []\n    for paragraph in doc.paragraphs:\n        try:\n            text = clean_text(paragraph.text)\n            if text:",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "extract_text_from_image",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def extract_text_from_image(image_bytes: bytes) -> List[Tuple[int, str]]:\n    image = Image.open(io.BytesIO(image_bytes))\n    text = pytesseract.image_to_string(image).strip()\n    clean = clean_text(text)\n    return [(1, clean)]\ndef normalize_file_type(mime_type: str) -> str:\n    if mime_type.startswith(\"image/\"):\n        return \"image\"\n    ext = mimetypes.guess_extension(mime_type)\n    if not ext:",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "normalize_file_type",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def normalize_file_type(mime_type: str) -> str:\n    if mime_type.startswith(\"image/\"):\n        return \"image\"\n    ext = mimetypes.guess_extension(mime_type)\n    if not ext:\n        raise ValueError(f\"Unknown MIME type: {mime_type}\")\n    ext = ext.lstrip(\".\").lower()\n    return ext\ndef process_document_for_text(file_bytes: bytes, mime_type: str) -> List[Tuple[int, str]]:\n    handlers = {",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "process_document_for_text",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def process_document_for_text(file_bytes: bytes, mime_type: str) -> List[Tuple[int, str]]:\n    handlers = {\n        \"pdf\": extract_text_from_pdf,\n        \"docx\": extract_text_from_docx,\n        \"img\": extract_text_from_image\n        # Add more handlers here as you support new file types\n    }\n    file_type = normalize_file_type(mime_type)\n    handler = handlers.get(file_type)\n    if not handler:",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "base64_to_text",
        "kind": 2,
        "importPath": "backend.app.services.document_processor",
        "description": "backend.app.services.document_processor",
        "peekOfCode": "def base64_to_text(base64_text: str, mime_type: str) -> List[Tuple[int, str]]:\n    file_bytes = base64.b64decode(base64_text)\n    return process_document_for_text(file_bytes, mime_type)",
        "detail": "backend.app.services.document_processor",
        "documentation": {}
    },
    {
        "label": "chunk_pages_with_recursive_chunker",
        "kind": 2,
        "importPath": "backend.app.services.embedding",
        "description": "backend.app.services.embedding",
        "peekOfCode": "def chunk_pages_with_recursive_chunker(\n    pages: List[Tuple[int, str]],\n    chunk_size: int = 500,\n    chunk_overlap: int = 50\n) -> List[Tuple[int, str]]:\n    chunker = RecursiveChunker(chunk_size=chunk_size)\n    chunks = []\n    page_numbers = []\n    for page_number, page_text in pages:\n        if not page_text.strip():",
        "detail": "backend.app.services.embedding",
        "documentation": {}
    },
    {
        "label": "get_embeddings",
        "kind": 2,
        "importPath": "backend.app.services.embedding",
        "description": "backend.app.services.embedding",
        "peekOfCode": "def get_embeddings(chunks: list[str]) -> list[list[float]]:\n    embeddings = model.encode(chunks, normalize_embeddings=True)\n    return embeddings.tolist()",
        "detail": "backend.app.services.embedding",
        "documentation": {}
    },
    {
        "label": "EMBEDDING_MODEL_NAME",
        "kind": 5,
        "importPath": "backend.app.services.embedding",
        "description": "backend.app.services.embedding",
        "peekOfCode": "EMBEDDING_MODEL_NAME = os.getenv(\"EMBEDDING_MODEL\", \"all-MiniLM-L6-v2\")\nmodel = SentenceTransformer(EMBEDDING_MODEL_NAME)\n# def chunk_text_recursive(text: str, chunk_size=500, chunk_overlap=50) -> list[str]:\n#     chunker = RecursiveChunker(chunk_size=chunk_size, overlap=chunk_overlap)\n#     chunks = chunker(text)\n#     return [chunk.text for chunk in chunks]\ndef chunk_pages_with_recursive_chunker(\n    pages: List[Tuple[int, str]],\n    chunk_size: int = 500,\n    chunk_overlap: int = 50",
        "detail": "backend.app.services.embedding",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "backend.app.services.embedding",
        "description": "backend.app.services.embedding",
        "peekOfCode": "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n# def chunk_text_recursive(text: str, chunk_size=500, chunk_overlap=50) -> list[str]:\n#     chunker = RecursiveChunker(chunk_size=chunk_size, overlap=chunk_overlap)\n#     chunks = chunker(text)\n#     return [chunk.text for chunk in chunks]\ndef chunk_pages_with_recursive_chunker(\n    pages: List[Tuple[int, str]],\n    chunk_size: int = 500,\n    chunk_overlap: int = 50\n) -> List[Tuple[int, str]]:",
        "detail": "backend.app.services.embedding",
        "documentation": {}
    },
    {
        "label": "save_file",
        "kind": 2,
        "importPath": "backend.app.services.file_service",
        "description": "backend.app.services.file_service",
        "peekOfCode": "def save_file(upload_file: UploadFile, user_id: uuid.UUID) -> str:\n    extension = Path(upload_file.filename).suffix\n    unique_filename = f\"{upload_file.filename}\"\n    user_dir = Path(UPLOAD_DIR) / str(user_id)\n    user_dir.mkdir(parents=True, exist_ok=True)\n    file_path = user_dir / unique_filename\n    upload_file.file.seek(0)\n    file_bytes = upload_file.file.read()\n    if not file_bytes:\n        raise ValueError(\"Uploaded file is empty\")",
        "detail": "backend.app.services.file_service",
        "documentation": {}
    },
    {
        "label": "save_base64_file",
        "kind": 2,
        "importPath": "backend.app.services.file_service",
        "description": "backend.app.services.file_service",
        "peekOfCode": "def save_base64_file(content_base64: str, filename: str, user_id: uuid.UUID) -> str:\n    user_folder = Path(UPLOAD_DIR) / str(user_id)\n    user_folder.mkdir(parents=True, exist_ok=True)\n    extension = Path(filename).suffix\n    # unique_filename = f\"{uuid.uuid4()}{extension}\"\n    unique_filename = f\"{filename}\"\n    file_path = user_folder / unique_filename\n    file_bytes = base64.b64decode(content_base64)\n    with file_path.open(\"wb\") as f:\n        f.write(file_bytes)",
        "detail": "backend.app.services.file_service",
        "documentation": {}
    },
    {
        "label": "UPLOAD_DIR",
        "kind": 5,
        "importPath": "backend.app.services.file_service",
        "description": "backend.app.services.file_service",
        "peekOfCode": "UPLOAD_DIR = os.getenv(\"UPLOAD_DIR\", \"/app/uploads\")\nPath(UPLOAD_DIR).mkdir(parents=True, exist_ok=True)\ndef save_file(upload_file: UploadFile, user_id: uuid.UUID) -> str:\n    extension = Path(upload_file.filename).suffix\n    unique_filename = f\"{upload_file.filename}\"\n    user_dir = Path(UPLOAD_DIR) / str(user_id)\n    user_dir.mkdir(parents=True, exist_ok=True)\n    file_path = user_dir / unique_filename\n    upload_file.file.seek(0)\n    file_bytes = upload_file.file.read()",
        "detail": "backend.app.services.file_service",
        "documentation": {}
    },
    {
        "label": "detect_language",
        "kind": 2,
        "importPath": "backend.app.services.metadata_extractor",
        "description": "backend.app.services.metadata_extractor",
        "peekOfCode": "def detect_language(text: str) -> str:\n    try:\n        return detect(text)\n    except:\n        return \"unknown\"\ndef extract_topics(text: str, top_n=3) -> list:\n    try:\n        keywords = kw_model.extract_keywords(text, top_n=top_n)\n        return [kw[0] for kw in keywords]\n    except:",
        "detail": "backend.app.services.metadata_extractor",
        "documentation": {}
    },
    {
        "label": "extract_topics",
        "kind": 2,
        "importPath": "backend.app.services.metadata_extractor",
        "description": "backend.app.services.metadata_extractor",
        "peekOfCode": "def extract_topics(text: str, top_n=3) -> list:\n    try:\n        keywords = kw_model.extract_keywords(text, top_n=top_n)\n        return [kw[0] for kw in keywords]\n    except:\n        return []\ndef infer_heading_from_context(chunk: str, previous_lines: list[str]) -> str:\n    for line in reversed(previous_lines[-5:]):\n        if len(line.strip()) < 100:\n            if line.isupper() or re.match(r'^[A-Z][A-Za-z0-9\\s\\-:]{2,}$', line):",
        "detail": "backend.app.services.metadata_extractor",
        "documentation": {}
    },
    {
        "label": "infer_heading_from_context",
        "kind": 2,
        "importPath": "backend.app.services.metadata_extractor",
        "description": "backend.app.services.metadata_extractor",
        "peekOfCode": "def infer_heading_from_context(chunk: str, previous_lines: list[str]) -> str:\n    for line in reversed(previous_lines[-5:]):\n        if len(line.strip()) < 100:\n            if line.isupper() or re.match(r'^[A-Z][A-Za-z0-9\\s\\-:]{2,}$', line):\n                return line.strip()\n    return \"\"\ndef create_metadata(\n    chunks: list[str], \n    page_numbers: list[int], \n    document_id: str,",
        "detail": "backend.app.services.metadata_extractor",
        "documentation": {}
    },
    {
        "label": "create_metadata",
        "kind": 2,
        "importPath": "backend.app.services.metadata_extractor",
        "description": "backend.app.services.metadata_extractor",
        "peekOfCode": "def create_metadata(\n    chunks: list[str], \n    page_numbers: list[int], \n    document_id: str,\n    filename: str,\n    mime_type: str\n) -> list[dict]:\n    metadata_list = []\n    for i, (chunk, page_number) in enumerate(zip(chunks, page_numbers)):\n        heading = infer_heading_from_context(chunk, chunks[:i])",
        "detail": "backend.app.services.metadata_extractor",
        "documentation": {}
    },
    {
        "label": "kw_model",
        "kind": 5,
        "importPath": "backend.app.services.metadata_extractor",
        "description": "backend.app.services.metadata_extractor",
        "peekOfCode": "kw_model = KeyBERT()\ndef detect_language(text: str) -> str:\n    try:\n        return detect(text)\n    except:\n        return \"unknown\"\ndef extract_topics(text: str, top_n=3) -> list:\n    try:\n        keywords = kw_model.extract_keywords(text, top_n=top_n)\n        return [kw[0] for kw in keywords]",
        "detail": "backend.app.services.metadata_extractor",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "kind": 2,
        "importPath": "backend.app.services.ollama_client",
        "description": "backend.app.services.ollama_client",
        "peekOfCode": "def generate_response(query: str, context: str, stream: bool) -> str:\n    # promt = f\"\"\"Instruction: Use the context to answer the question. If there is no sufficient information in context, use your knowledge.\n    # Question: {query}\n    # Context: {context}\"\"\"\n    prompt_template = \"\"\"<|im_start|>system\nYou are a highly knowledgeable and accurate RAG system. Your primary goal is to provide concise and comprehensive answers to user questions based on the provided context. Follow these rules precisely:\n1.  **Prioritize the Context:** Your answer must be based *exclusively* on the information found in the `<context>` section. Do not use any external knowledge.\n2.  **No Sufficient Information:** If the `<context>` does not contain the answer, you must respond with a specific phrase indicating this, such as \"I'm sorry, I cannot answer this question with the provided context.\" or \"The provided context does not contain sufficient information to answer the question.\"\n3.  **Synthesize and Summarize:** If the answer is present, synthesize the relevant information from the context into a clear, direct, and well-structured response.\n4.  **Stay on Topic:** Your answer should directly address the user's question and avoid adding any unrelated details.",
        "detail": "backend.app.services.ollama_client",
        "documentation": {}
    },
    {
        "label": "OLLAMA_URL",
        "kind": 5,
        "importPath": "backend.app.services.ollama_client",
        "description": "backend.app.services.ollama_client",
        "peekOfCode": "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\nMODEL = os.getenv(\"LLM_MODEL_NAME\", \"qwen3:0.6b\")\ndef generate_response(query: str, context: str, stream: bool) -> str:\n    # promt = f\"\"\"Instruction: Use the context to answer the question. If there is no sufficient information in context, use your knowledge.\n    # Question: {query}\n    # Context: {context}\"\"\"\n    prompt_template = \"\"\"<|im_start|>system\nYou are a highly knowledgeable and accurate RAG system. Your primary goal is to provide concise and comprehensive answers to user questions based on the provided context. Follow these rules precisely:\n1.  **Prioritize the Context:** Your answer must be based *exclusively* on the information found in the `<context>` section. Do not use any external knowledge.\n2.  **No Sufficient Information:** If the `<context>` does not contain the answer, you must respond with a specific phrase indicating this, such as \"I'm sorry, I cannot answer this question with the provided context.\" or \"The provided context does not contain sufficient information to answer the question.\"",
        "detail": "backend.app.services.ollama_client",
        "documentation": {}
    },
    {
        "label": "MODEL",
        "kind": 5,
        "importPath": "backend.app.services.ollama_client",
        "description": "backend.app.services.ollama_client",
        "peekOfCode": "MODEL = os.getenv(\"LLM_MODEL_NAME\", \"qwen3:0.6b\")\ndef generate_response(query: str, context: str, stream: bool) -> str:\n    # promt = f\"\"\"Instruction: Use the context to answer the question. If there is no sufficient information in context, use your knowledge.\n    # Question: {query}\n    # Context: {context}\"\"\"\n    prompt_template = \"\"\"<|im_start|>system\nYou are a highly knowledgeable and accurate RAG system. Your primary goal is to provide concise and comprehensive answers to user questions based on the provided context. Follow these rules precisely:\n1.  **Prioritize the Context:** Your answer must be based *exclusively* on the information found in the `<context>` section. Do not use any external knowledge.\n2.  **No Sufficient Information:** If the `<context>` does not contain the answer, you must respond with a specific phrase indicating this, such as \"I'm sorry, I cannot answer this question with the provided context.\" or \"The provided context does not contain sufficient information to answer the question.\"\n3.  **Synthesize and Summarize:** If the answer is present, synthesize the relevant information from the context into a clear, direct, and well-structured response.",
        "detail": "backend.app.services.ollama_client",
        "documentation": {}
    },
    {
        "label": "ensure_collection",
        "kind": 2,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "def ensure_collection():\n    if COLLECTION_NAME not in [c.name for c in client.get_collections().collections]:\n        client.create_collection(\n            collection_name=COLLECTION_NAME,\n            vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n        )\ndef store_document(\n        chunks: list, \n        embeddings: list, \n        metadata: list[dict],",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "store_document",
        "kind": 2,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "def store_document(\n        chunks: list, \n        embeddings: list, \n        metadata: list[dict],\n    ):\n    ensure_collection()\n    client.upsert(\n        collection_name=COLLECTION_NAME,\n        points=[\n            PointStruct(",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "delete_document",
        "kind": 2,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "def delete_document(doc_id: uuid.UUID):\n    ensure_collection()\n    client.delete(\n        collection_name=COLLECTION_NAME,\n        points_selector=qmodels.FilterSelector(\n            filter=qmodels.Filter(\n                must=[\n                    qmodels.FieldCondition(\n                        key=\"document_id\",\n                        match=qmodels.MatchValue(value=str(doc_id))",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "query_top_k",
        "kind": 2,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "def query_top_k(query_vector, user_id, k=5):\n    ensure_collection()\n    # TODO Use metadata to better search\n    results = client.search(\n        collection_name=COLLECTION_NAME,\n        query_vector=query_vector,\n        limit=k,\n        with_payload=True,\n        # query_filter={\n        #     \"must\": [",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "client = QdrantClient(host=\"qdrant\", port=6333)\nCOLLECTION_NAME = \"documents\"\ndef ensure_collection():\n    if COLLECTION_NAME not in [c.name for c in client.get_collections().collections]:\n        client.create_collection(\n            collection_name=COLLECTION_NAME,\n            vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n        )\ndef store_document(\n        chunks: list, ",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "COLLECTION_NAME",
        "kind": 5,
        "importPath": "backend.app.services.qdrant_client",
        "description": "backend.app.services.qdrant_client",
        "peekOfCode": "COLLECTION_NAME = \"documents\"\ndef ensure_collection():\n    if COLLECTION_NAME not in [c.name for c in client.get_collections().collections]:\n        client.create_collection(\n            collection_name=COLLECTION_NAME,\n            vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n        )\ndef store_document(\n        chunks: list, \n        embeddings: list, ",
        "detail": "backend.app.services.qdrant_client",
        "documentation": {}
    },
    {
        "label": "read_root",
        "kind": 2,
        "importPath": "backend.app.main",
        "description": "backend.app.main",
        "peekOfCode": "def read_root():\n    return {\"message\": \"FastAPI is running!\"}\n# @app.get(\"/items/{item_id}\")\n# def read_item(item_id: int, q: str = None):\n#     return {\"item_id\": item_id, \"q\": q}",
        "detail": "backend.app.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app.main",
        "description": "backend.app.main",
        "peekOfCode": "app = FastAPI()\napp.include_router(upload.router, prefix=\"/upload\")\napp.include_router(chat.router, prefix=\"/chat\")\napp.include_router(documents.router, prefix=\"/documents\")\n@app.get(\"/\")\ndef read_root():\n    return {\"message\": \"FastAPI is running!\"}\n# @app.get(\"/items/{item_id}\")\n# def read_item(item_id: int, q: str = None):\n#     return {\"item_id\": item_id, \"q\": q}",
        "detail": "backend.app.main",
        "documentation": {}
    },
    {
        "label": "User",
        "kind": 6,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "class User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)\n    last_name = Column(String)\n    created_at = Column(TIMESTAMP, server_default=\"NOW()\")\nclass Document(Base):\n    __tablename__ = \"documents\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "Document",
        "kind": 6,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "class Document(Base):\n    __tablename__ = \"documents\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    filename = Column(String, nullable=False)\n    file_path = Column(String, nullable=False)\n    mime_type = Column(String, nullable=False)\n    uploaded_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"))\n    upload_date = Column(TIMESTAMP, server_default=\"NOW()\")\ndef database_is_empty(engine):\n    inspector = inspect(engine)",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "database_is_empty",
        "kind": 2,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "def database_is_empty(engine):\n    inspector = inspect(engine)\n    tables = inspector.get_table_names()\n    return not any(t in tables for t in [\"users\", \"documents\"])\ndef create_tables():\n    with engine.connect() as conn:\n        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS pgcrypto;\"))\n    Base.metadata.create_all(engine)\n    print(\"Tables created successfully!\")\ndef insert_test_user():",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "create_tables",
        "kind": 2,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "def create_tables():\n    with engine.connect() as conn:\n        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS pgcrypto;\"))\n    Base.metadata.create_all(engine)\n    print(\"Tables created successfully!\")\ndef insert_test_user():\n    session = SessionLocal()\n    try:\n        user_count = session.query(User).count()\n        if user_count == 0 and TEST_USER_EMAIL:",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "insert_test_user",
        "kind": 2,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "def insert_test_user():\n    session = SessionLocal()\n    try:\n        user_count = session.query(User).count()\n        if user_count == 0 and TEST_USER_EMAIL:\n            test_user = User(\n                email=TEST_USER_EMAIL,\n                first_name=TEST_USER_FIRST,\n                last_name=TEST_USER_LAST\n            )",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "DATABASE_URL",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "DATABASE_URL = os.environ.get(\"DATABASE_URL\")\nif not DATABASE_URL:\n    raise ValueError(\"DATABASE_URL is not set in environment\")\nTEST_USER_EMAIL = os.environ.get(\"TEST_USER_EMAIL\")\nTEST_USER_FIRST = os.environ.get(\"TEST_USER_FIRST\", \"Test\")\nTEST_USER_LAST = os.environ.get(\"TEST_USER_LAST\", \"User\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "TEST_USER_EMAIL",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "TEST_USER_EMAIL = os.environ.get(\"TEST_USER_EMAIL\")\nTEST_USER_FIRST = os.environ.get(\"TEST_USER_FIRST\", \"Test\")\nTEST_USER_LAST = os.environ.get(\"TEST_USER_LAST\", \"User\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "TEST_USER_FIRST",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "TEST_USER_FIRST = os.environ.get(\"TEST_USER_FIRST\", \"Test\")\nTEST_USER_LAST = os.environ.get(\"TEST_USER_LAST\", \"User\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "TEST_USER_LAST",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "TEST_USER_LAST = os.environ.get(\"TEST_USER_LAST\", \"User\")\nengine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)\n    last_name = Column(String)",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "engine",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "engine = create_engine(DATABASE_URL)\nSessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)\n    last_name = Column(String)\n    created_at = Column(TIMESTAMP, server_default=\"NOW()\")",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "SessionLocal",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "SessionLocal = sessionmaker(bind=engine)\nBase = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)\n    last_name = Column(String)\n    created_at = Column(TIMESTAMP, server_default=\"NOW()\")\nclass Document(Base):",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    },
    {
        "label": "Base",
        "kind": 5,
        "importPath": "backend.db_init.db_init",
        "description": "backend.db_init.db_init",
        "peekOfCode": "Base = declarative_base()\nclass User(Base):\n    __tablename__ = \"users\"\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    email = Column(String, unique=True, nullable=False)\n    first_name = Column(String)\n    last_name = Column(String)\n    created_at = Column(TIMESTAMP, server_default=\"NOW()\")\nclass Document(Base):\n    __tablename__ = \"documents\"",
        "detail": "backend.db_init.db_init",
        "documentation": {}
    }
]